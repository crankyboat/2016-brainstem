{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from matplotlib.path import Path\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['BackG', '5N', '7n', '7N', '12N', 'Pn', 'VLL', \n",
    "          '6N', 'Amb', 'R', 'Tz', 'RtTg', 'LRt', 'LC', 'AP', 'sp5']\n",
    "\n",
    "n_labels = len(labels)\n",
    "\n",
    "labels_index = dict((j, i) for i, j in enumerate(labels))\n",
    "\n",
    "labels_from_surround = dict( (l+'_surround', l) for l in labels[1:])\n",
    "\n",
    "labels_surroundIncluded_list = labels[1:] + [l+'_surround' for l in labels[1:]]\n",
    "labels_surroundIncluded = set(labels_surroundIncluded_list)\n",
    "\n",
    "labels_surroundIncluded_index = dict((j, i) for i, j in enumerate(labels_surroundIncluded_list))\n",
    "\n",
    "# colors = np.random.randint(0, 255, (len(labels_index), 3))\n",
    "# colors = np.loadtxt(os.environ['REPO_DIR'] + '/visualization/100colors.txt')\n",
    "# colors[labels_index['BackG']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BackG', 5105) Train:  800 Test:  200\n",
      "('5N', 1440) Train:  800 Test:  200\n",
      "('7n', 3444) Train:  800 Test:  200\n",
      "('7N', 2579) Train:  800 Test:  200\n",
      "('12N', 1230) Train:  800 Test:  200\n",
      "('Pn', 3042) Train:  800 Test:  200\n",
      "('VLL', 1287) Train:  800 Test:  200\n",
      "('6N', 154) Train:  123 Test:  31\n",
      "('Amb', 346) Train:  276 Test:  70\n",
      "('R', 1082) Train:  800 Test:  200\n",
      "('Tz', 1387) Train:  800 Test:  200\n",
      "('RtTg', 2639) Train:  800 Test:  200\n",
      "('LRt', 1050) Train:  800 Test:  200\n",
      "('LC', 481) Train:  384 Test:  97\n",
      "('AP', 483) Train:  386 Test:  97\n",
      "('sp5', 3240) Train:  800 Test:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load time: 0.134404 seconds\n"
     ]
    }
   ],
   "source": [
    "# build training data\n",
    "t = time.time()\n",
    "\n",
    "sift_dir = '/oasis/projects/nsf/csd395/wel144/2016-brainstem/sift-jpeg'\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "train_fnames = []\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "test_fnames = []\n",
    "\n",
    "n_sample = 1000\n",
    "\n",
    "for name in labels:\n",
    "\n",
    "    files = bp.unpack_ndarray_file(sift_dir + '/train/MD589_%(name)s_fnames.bp' % {'name': name})\n",
    "    hists0 = bp.unpack_ndarray_file(sift_dir + '/train/MD589_%(name)s_histograms_l0.bp' % {'name': name})\n",
    "#     hists1 = bp.unpack_ndarray_file(sift_dir + '/train/MD589_%(name)s_histograms_l1.bp' % {'name': name})\n",
    "#     hists2 = bp.unpack_ndarray_file(sift_dir + '/train/MD589_%(name)s_histograms_l2.bp' % {'name': name})\n",
    "#     print (hists0.shape, hists1.shape, hists2.shape, files.shape)\n",
    "    \n",
    "    n_total = hists0.shape[0]\n",
    "    print (name, n_total),\n",
    "\n",
    "    random_indices = np.random.choice(range(n_total), min(n_total, n_sample), replace=False)\n",
    "    \n",
    "    frac = int(0.8*len(random_indices))\n",
    "    random_train = random_indices[:frac]\n",
    "    random_test = random_indices[frac:]\n",
    "    n_train = len(random_train)\n",
    "    n_test = len(random_test)\n",
    "    \n",
    "#     train_hists = np.c_[hists0[random_train], \n",
    "#                         hists1[random_train].reshape((n_train, -1)), \n",
    "#                         hists2[random_train].reshape((n_train, -1))]\n",
    "#     test_hists =  np.c_[hists0[random_test], \n",
    "#                         hists1[random_test].reshape((n_test, -1)), \n",
    "#                         hists2[random_test].reshape((n_test, -1))]\n",
    "    train_hists = np.c_[hists0[random_train]]\n",
    "    test_hists =  np.c_[hists0[random_test]]\n",
    "    \n",
    "    train_files = files[random_train].reshape((n_train,))\n",
    "    test_files = files[random_test].reshape((n_test,))\n",
    "    \n",
    "    train_data.append(train_hists)\n",
    "    train_labels.append(np.ones((n_train, )) * labels_index[name])\n",
    "    train_fnames.append(train_files)\n",
    "    \n",
    "    test_data.append(test_hists)\n",
    "    test_labels.append(np.ones((n_test, )) * labels_index[name])\n",
    "    test_fnames.append(test_files)\n",
    "    \n",
    "    print 'Train: ', n_train, \n",
    "    print 'Test: ', n_test\n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "train_fnames = np.concatenate(train_fnames)\n",
    "n_train = train_data.shape[0]\n",
    "\n",
    "test_data = np.concatenate(test_data)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "test_fnames = np.concatenate(test_fnames)\n",
    "n_test = test_data.shape[0]\n",
    "\n",
    "sys.stderr.write('Load time: %f seconds\\n' % (time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10769, 200)\n",
      "(10769,)\n",
      "(10769,) |S255\n",
      "/oasis/projects/nsf/csd395/wel144/2016-brainstem/sift-jpeg/train/MD589/MD589_BackG_0271_0028.png\n",
      "(2695, 200)\n",
      "(2695,)\n",
      "(2695,) |S255\n",
      "/oasis/projects/nsf/csd395/wel144/2016-brainstem/sift-jpeg/train/MD589/MD589_BackG_0281_0014.png\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_labels.shape\n",
    "print train_fnames.shape, train_fnames.dtype\n",
    "print train_fnames[0]\n",
    "\n",
    "print test_data.shape\n",
    "print test_labels.shape\n",
    "print test_fnames.shape, test_fnames.dtype\n",
    "print test_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/__main__.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  if __name__ == '__main__':\n",
      "/oasis/projects/nsf/csd181/yuncong/virtualenv-1.9.1/yuncongve/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "train_data_normalized = train_data / train_data.sum(axis=1)[:,None].astype(np.float)\n",
    "train_data_normalized = np.nan_to_num(train_data_normalized)\n",
    "\n",
    "test_data_normalized = test_data / test_data.sum(axis=1)[:,None].astype(np.float)\n",
    "test_data_normalized = np.nan_to_num(test_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pack time: 0.133177 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "bp.pack_ndarray_file(train_data_normalized, sift_dir+'/preprocessed/train_data.bp')\n",
    "bp.pack_ndarray_file(train_labels, sift_dir+'/preprocessed/train_labels.bp')\n",
    "bp.pack_ndarray_file(train_fnames, sift_dir+'/preprocessed/train_fnames.bp', chunk_size=255*4000)\n",
    "\n",
    "bp.pack_ndarray_file(test_data_normalized, sift_dir+'/preprocessed/test_data.bp')\n",
    "bp.pack_ndarray_file(test_labels, sift_dir+'/preprocessed/test_labels.bp')\n",
    "bp.pack_ndarray_file(test_fnames, sift_dir+'/preprocessed/test_fnames.bp', chunk_size=255*4000)\n",
    "\n",
    "sys.stderr.write('Pack time: %f seconds\\n' % (time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute intersection kernel: 9.731474 seconds\n"
     ]
    }
   ],
   "source": [
    "# method 1\n",
    "t = time.time()\n",
    "\n",
    "def compute_intersection_kernel_oneJob(i, j1):\n",
    "#     dist = .5 * np.sum(train_data_normalized + h - np.abs(train_data_normalized - h), axis=1)\n",
    "    dist = np.minimum(train_data_normalized[i], train_data_normalized[j1:]).sum(axis=1)\n",
    "    return dist\n",
    "\n",
    "train_dist_triangle = np.concatenate(Parallel(n_jobs=16)(delayed(compute_intersection_kernel_oneJob)(i, i) \n",
    "                                     for i in range(n_train)))\n",
    "\n",
    "sys.stderr.write('compute intersection kernel: %f seconds\\n' % (time.time() - t)) # ~ 200s / 12k training data\n",
    "\n",
    "train_dist_mat = np.empty((n_train, n_train))\n",
    "train_dist_mat[np.triu_indices(n_train)] = train_dist_triangle\n",
    "r = np.tril_indices(n_train)\n",
    "train_dist_mat[r] = train_dist_mat.T[r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute intersection kernel: 0.000238 seconds\n"
     ]
    }
   ],
   "source": [
    "# # method 2\n",
    "# t = time.time()\n",
    "\n",
    "# def compute_intersection_kernel_oneJob(h):\n",
    "# #   dist = .5 * np.sum(train_data_normalized + h - np.abs(train_data_normalized - h), axis=1)\n",
    "#     dist = np.minimum(train_data_normalized, h).sum(axis=1)\n",
    "#     return dist\n",
    "\n",
    "# train_dist_mat = np.array(Parallel(n_jobs=16)(delayed(compute_intersection_kernel_oneJob)(h) \n",
    "#                                      for h in train_data_normalized[:1000]))\n",
    "\n",
    "# sys.stderr.write('compute intersection kernel: %f seconds\\n' % (time.time() - t)) # ~ 400s / 12k training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute intersection kernel: 0.000292 seconds\n"
     ]
    }
   ],
   "source": [
    "# # method 3\n",
    "# t = time.time()\n",
    "\n",
    "# def compute_intersection_kernel_oneJob(i, ni, j, nj):\n",
    "#     dists = np.minimum(train_data_normalized[i:i+ni, None], train_data_normalized[j:j+nj]).sum(axis=-1)\n",
    "#     return dists\n",
    "\n",
    "# train_dist_mat = np.empty((n_train, n_train))\n",
    "# ni = 100\n",
    "# nj = 100\n",
    "# for j in range(0, n_train, nj):\n",
    "#     train_dist_mat[:, j:j+nj] = np.concatenate(Parallel(n_jobs=16)(delayed(compute_intersection_kernel_oneJob)(i, ni, j, nj) \n",
    "#                                                     for i in range(0, n_train, ni)))\n",
    "\n",
    "# sys.stderr.write('compute intersection kernel: %f seconds\\n' % (time.time() - t)) # ~ 400s / 12k training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10769, 10769)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dist_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pack training kernel\n",
    "\n",
    "bp.pack_ndarray_file(train_dist_mat, sift_dir+'/preprocessed/train_spm_dist_mat.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Build unlabeled testing data\n",
    "\n",
    "# sift_dir = '/oasis/projects/nsf/csd395/wel144/2016-brainstem/sift-jpeg/test'\n",
    "# stack = 'MD585'\n",
    "\n",
    "# first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "# sec = first_detect_sec\n",
    "\n",
    "# test_hists0 = bp.unpack_ndarray_file(sift_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l0.bp' % {'stack': stack, 'sec': sec})\n",
    "# test_hists1 = bp.unpack_ndarray_file(sift_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l1.bp' % {'stack': stack, 'sec': sec})\n",
    "# test_hists2 = bp.unpack_ndarray_file(sift_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l2.bp' % {'stack': stack, 'sec': sec})\n",
    "# test_fcoords = bp.unpack_ndarray_file(sift_dir + '/%(stack)s_%(sec)04d_roi1_fcoords.bp' % {'stack': stack, 'sec': sec})\n",
    "\n",
    "# n_test = test_hists0.shape[0]\n",
    "# test_hists = np.c_[test_hists0, test_hists1.reshape((n_test, -1)), test_hists2.reshape((n_test, -1))]\n",
    "# test_data = test_hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print test_data.shape\n",
    "# print test_fcoords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_data_normalized = test_data / test_data.sum(axis=1)[:,None].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bp.pack_ndarray_file(test_data_normalized, sift_dir+'/preprocessed/%(stack)s_test_data.bp' % {'stack': stack})\n",
    "# bp.pack_ndarray_file(test_fcoords, sift_dir+'/preprocessed/%(stack)s_test_fcoords.bp' % {'stack': stack})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
