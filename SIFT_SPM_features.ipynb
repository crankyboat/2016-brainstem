{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "\n",
    "from matplotlib.path import Path\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack = 'MD589'\n",
    "stack = 'MD585'\n",
    "dm = DataManager(stack=stack)\n",
    "\n",
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /home/yuncong/CSHL_data_patches/MD585_indices_allROIs_allSections.h5 in read-only mode\n",
      "Opening /home/yuncong/CSHL_data_patches/MD585_indices_allROIs_allSections.h5 in read-only mode\n"
     ]
    }
   ],
   "source": [
    "# Load sample locations\n",
    "\n",
    "patches_rootdir = '/home/yuncong/CSHL_data_patches/'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "table_filepath = os.path.join(patches_rootdir, '%(stack)s_indices_allROIs_allSections.h5'%{'stack':stack})\n",
    "indices_allROIs_allSections = pd.read_hdf(table_filepath, 'indices_allROIs_allSections')\n",
    "grid_parameters = pd.read_hdf(table_filepath, 'grid_parameters')\n",
    "\n",
    "patch_size, stride, w, h = grid_parameters.tolist()\n",
    "half_size = patch_size/2\n",
    "ys, xs = np.meshgrid(np.arange(half_size, h-half_size, stride), np.arange(half_size, w-half_size, stride),\n",
    "                 indexing='xy')\n",
    "sample_locations = np.c_[xs.flat, ys.flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmin, ymin, w, h = detect_bbox_lookup[stack]\n",
    "xmin = xmin * 32\n",
    "ymin = ymin * 32\n",
    "w = w * 32\n",
    "h = h * 32\n",
    "xmax = xmin + w - 1\n",
    "ymax = ymin + h - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = '/oasis/projects/nsf/csd395/yuncong/Brain/learning/sift'\n",
    "M = 200 # vocabulary size\n",
    "colors = np.vstack([(0,0,0), np.random.randint(0, 255, (M, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load vocabulary (as a sklearn.KMeans object)\n",
    "\n",
    "if os.path.exists(output_dir + '/vocab.pkl'):\n",
    "    \n",
    "    # Load vocabulary\n",
    "    vocabulary = joblib.load(output_dir + '/vocab.pkl')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    if os.path.exists(output_dir + '/sift_descriptors_pool_arr.bp'):\n",
    "        \n",
    "        # Load descriptor pool\n",
    "        descriptors_pool_arr = bp.unpack_ndarray_file(output_dir + '/sift_descriptors_pool_arr.bp')\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        vocabulary = KMeans(init='random', n_clusters=M, n_init=10)\n",
    "        vocabulary.fit(descriptors_pool_arr)\n",
    "\n",
    "        sys.stderr.write('sift: %.2f seconds\\n' % (time.time() - t)) # 300 seconds\n",
    "\n",
    "        cluster_centers = vocabulary.cluster_centers_\n",
    "\n",
    "        joblib.dump(vocabulary, output_dir + '/vocab.pkl')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Generate SIFT descriptor pool\n",
    "        descriptors_pool = []\n",
    "\n",
    "        sift = cv2.SIFT();\n",
    "        \n",
    "        for sec in range(first_detect_sec, last_detect_sec+1, 10):\n",
    "\n",
    "            print sec\n",
    "\n",
    "            dm.set_slice(sec)\n",
    "            dm._load_image(versions=['rgb-jpg'])\n",
    "            img = dm.image_rgb_jpg[ymin:ymax+1, xmin:xmax+1]\n",
    "\n",
    "            keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "            n = 1000\n",
    "            random_indices = np.random.choice(range(len(descriptors)), n, replace=False)\n",
    "\n",
    "            descriptors_pool.append(descriptors[random_indices])\n",
    "\n",
    "        descriptors_pool_arr = np.vstack(descriptors_pool)\n",
    "        print len(descriptors_pool_arr), 'in descriptor pool'\n",
    "\n",
    "        bp.pack_ndarray_file(descriptors_pool_arr, output_dir + '/sift_descriptors_pool_arr.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create_if_not_exists(output_dir + '/%(stack)s' % {'stack': stack})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sec:  132\n",
      "Size of patches: (224.000000 by 224.000000)\n",
      "Num of patches:  20979\n",
      "Num of fcoords:  (20979, 6)\n",
      "(20979, 16, 200)\n",
      "(20979, 4, 200)\n",
      "(20979, 200)\n",
      "\n",
      "Sec:  133\n",
      "Size of patches: (224.000000 by 224.000000)\n",
      "Num of patches:  21122\n",
      "Num of fcoords:  (21122, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 18.027752 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21122, 16, 200)\n",
      "(21122, 4, 200)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done in 18.012727 seconds\n",
      "Total done in 37.969029 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(21122, 200)\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.SIFT();\n",
    "\n",
    "first_detect_sec, last_detect_sec = detect_bbox_range_lookup[stack]\n",
    "\n",
    "progress_bar = FloatProgress(min=first_detect_sec, max=last_detect_sec)\n",
    "display(progress_bar)\n",
    "\n",
    "total_t = time.time()\n",
    "\n",
    "# for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "for sec in [first_detect_sec, first_detect_sec+1]:\n",
    "    \n",
    "    progress_bar.value = sec\n",
    "    \n",
    "    labelmap_fp = output_dir + '/%(stack)s/%(stack)s_%(sec)04d_labelmap.hdf' % {'stack': stack, 'sec': sec}\n",
    "    \n",
    "    if os.path.exists(labelmap_fp):\n",
    "        \n",
    "        # Load labelmap\n",
    "        labelmap = load_hdf(labelmap_fp)\n",
    "#     else:\n",
    "        \n",
    "#         # Compute keypoints and assign labels\n",
    "\n",
    "#         dm.set_slice(sec)\n",
    "#         dm._load_image(versions=['rgb-jpg'])\n",
    "\n",
    "#         img = dm.image_rgb_jpg[ymin:ymax+1, xmin:xmax+1]\n",
    "\n",
    "#         t = time.time()\n",
    "#         keypoints, descriptors = sift.detectAndCompute(img, None); # 128 dim descriptor ï½ž 120 seconds\n",
    "#         sys.stderr.write('sift: %.2f seconds\\n' % (time.time() - t)) \n",
    "\n",
    "#         keypoints_arr = np.array([k.pt for k in keypoints])\n",
    "#         print len(keypoints), 'keypoints' # ~ 500k\n",
    "\n",
    "#         t = time.time()\n",
    "#         keypoint_labels = vocabulary.predict(descriptors)\n",
    "#         sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))  # ~ 20 s\n",
    "\n",
    "#         # visualize keypoints (color indicating label)\n",
    "\n",
    "#         # viz = img.copy()\n",
    "#         # for (x, y), l in zip(keypoints_arr, keypoint_labels):\n",
    "#         #     cv2.circle(viz, (int(x), int(y)), 3, colors[l], -1)\n",
    "#         # display_image(viz)\n",
    "\n",
    "#         # generate labelmap\n",
    "\n",
    "#         labelmap = np.zeros(dm.image_rgb_jpg.shape[:2], np.int)\n",
    "#         keypoints_arr_int = np.floor(keypoints_arr + (xmin, ymin)).astype(np.int)  # coords on original image\n",
    "#         labelmap[keypoints_arr_int[:,1], keypoints_arr_int[:,0]] = keypoint_labels + 1\n",
    "\n",
    "#         save_hdf(labelmap, labelmap_fp)\n",
    "        \n",
    "    \n",
    "    indices_roi = indices_allROIs_allSections[sec]['roi1']\n",
    "\n",
    "\n",
    "    # Compute histograms (method 2), for all levels\n",
    "\n",
    "    sample_locs_roi = sample_locations[indices_roi]\n",
    "    \n",
    "    # MY ADDITION\n",
    "    # compute level-0 jpeg\n",
    "    l = 0\n",
    "    grid_size = patch_size / 2**l\n",
    "    rx = [-.5]\n",
    "    ry = [-.5]\n",
    "    rxs, rys = np.meshgrid(rx, ry)\n",
    "    patch_coords_allGrid = []\n",
    "    for grid_i, (rx, ry) in enumerate(np.c_[rxs.flat, rys.flat]):\n",
    "        patch_xmin = sample_locs_roi[:,0] + rx * grid_size\n",
    "        patch_ymin = sample_locs_roi[:,1] + ry * grid_size\n",
    "        patch_xmax = sample_locs_roi[:,0] + (rx + 1) * grid_size\n",
    "        patch_ymax = sample_locs_roi[:,1] + (ry + 1) * grid_size\n",
    "        patch_coords_allGrid.append([patch_xmin, patch_ymin, patch_xmax, patch_ymax])\n",
    "    all_coords = np.hstack(patch_coords_allGrid)\n",
    "    patch_xmin = all_coords[0]\n",
    "    patch_ymin = all_coords[1]\n",
    "    patch_xmax = all_coords[2]\n",
    "    patch_ymax = all_coords[3]\n",
    "    mydir = '/oasis/projects/nsf/csd395/wel144/2016-brainstem/sift-jpeg/test'\n",
    "    fcoords = np.vstack([[sec, p, patch_xmin[p], patch_ymin[p], patch_xmax[p], patch_ymax[p]] for p in xrange(len(patch_xmin))])\n",
    "    print ''\n",
    "    print 'Sec: ', sec\n",
    "    print 'Size of patches: (%f by %f)' % (abs(patch_xmax[0]-patch_xmin[0]), abs(patch_ymax[0]-patch_ymin[0]))\n",
    "    print 'Num of patches: ', len(patch_xmin)\n",
    "    print 'Num of fcoords: ', fcoords.shape\n",
    "    # MY ADDITION END\n",
    "\n",
    "    # compute level-2 histograms\n",
    "    l = 2\n",
    "\n",
    "    grid_size = patch_size / 2**l\n",
    "\n",
    "    if l == 2:\n",
    "        rx = [-2, -1, 0, 1]\n",
    "        ry = [-2, -1, 0, 1]\n",
    "    elif l == 1:\n",
    "        rx = [-1, 0]\n",
    "        ry = [-1, 0]\n",
    "    elif l == 0:\n",
    "        rx = [-.5]\n",
    "        ry = [-.5]\n",
    "\n",
    "    rxs, rys = np.meshgrid(rx, ry)\n",
    "\n",
    "    patch_coords_allGrid = []\n",
    "\n",
    "    for grid_i, (rx, ry) in enumerate(np.c_[rxs.flat, rys.flat]):\n",
    "\n",
    "        patch_xmin = sample_locs_roi[:,0] + rx * grid_size\n",
    "        patch_ymin = sample_locs_roi[:,1] + ry * grid_size\n",
    "        patch_xmax = sample_locs_roi[:,0] + (rx + 1) * grid_size\n",
    "        patch_ymax = sample_locs_roi[:,1] + (ry + 1) * grid_size\n",
    "\n",
    "        patch_coords_allGrid.append([patch_xmin, patch_ymin, patch_xmax, patch_ymax])\n",
    "\n",
    "\n",
    "    all_coords = np.hstack(patch_coords_allGrid)\n",
    "    patch_xmin = all_coords[0]\n",
    "    patch_ymin = all_coords[1]\n",
    "    patch_xmax = all_coords[2]\n",
    "    patch_ymax = all_coords[3]\n",
    "\n",
    "    def compute_histogram_particular_label(i):\n",
    "        m = (labelmap == i).astype(np.uint8)\n",
    "        mi = cv2.integral(m)\n",
    "        ci = mi[patch_ymin, patch_xmin] + mi[patch_ymax, patch_xmax] - mi[patch_ymax, patch_xmin] - mi[patch_ymin, patch_xmax]\n",
    "        return ci\n",
    "\n",
    "    t = time.time()\n",
    "    hists = Parallel(n_jobs=16)(delayed(compute_histogram_particular_label)(i) for i in range(1, M+1))\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # ~ 18 seconds\n",
    "\n",
    "    n_grid = (2**l)**2\n",
    "    hists_arr2 = np.transpose(np.reshape(hists, (M, n_grid, -1)))\n",
    "    print hists_arr2.shape\n",
    "\n",
    "    # compute level-1 histograms based on level-2 histograms\n",
    "\n",
    "    hists_arr1 = np.transpose([hists_arr2[:, [0,1,4,5], :].sum(axis=1),\n",
    "                               hists_arr2[:, [2,3,6,7], :].sum(axis=1),\n",
    "                               hists_arr2[:, [8,9,12,13], :].sum(axis=1),\n",
    "                               hists_arr2[:, [10,11,14,15], :].sum(axis=1)], \n",
    "                              [1,0,2])\n",
    "    print hists_arr1.shape\n",
    "\n",
    "    # compute level-0 histograms based on level-1 histograms\n",
    "\n",
    "    hists_arr0 = hists_arr1.sum(axis=1)\n",
    "    print hists_arr0.shape\n",
    "    \n",
    "    # MY ADDITION\n",
    "    output_dir = '/oasis/projects/nsf/csd395/wel144/2016-brainstem/sift-jpeg/test'\n",
    "    bp.pack_ndarray_file(hists_arr0, output_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l0.bp' % {'stack': stack, 'sec': sec})\n",
    "    bp.pack_ndarray_file(hists_arr1, output_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l1.bp' % {'stack': stack, 'sec': sec})\n",
    "    bp.pack_ndarray_file(hists_arr2, output_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l2.bp' % {'stack': stack, 'sec': sec})\n",
    "    bp.pack_ndarray_file(fcoords, output_dir + '/%(stack)s_%(sec)04d_roi1_fcoords.bp' % {'stack': stack, 'sec': sec})\n",
    "    # MY ADDITION END\n",
    "\n",
    "#     bp.pack_ndarray_file(hists_arr0, output_dir + '/%(stack)s/%(stack)s_%(sec)04d_roi1_histograms_l0.bp' % {'stack': stack, 'sec': sec})\n",
    "#     bp.pack_ndarray_file(hists_arr1, output_dir + '/%(stack)s/%(stack)s_%(sec)04d_roi1_histograms_l1.bp' % {'stack': stack, 'sec': sec})\n",
    "#     bp.pack_ndarray_file(hists_arr2, output_dir + '/%(stack)s/%(stack)s_%(sec)04d_roi1_histograms_l2.bp' % {'stack': stack, 'sec': sec})\n",
    "\n",
    "    # save_hdf(hists_arr0, output_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l0.hdf' % {'stack': stack, 'sec': sec})\n",
    "    # save_hdf(hists_arr1, output_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l1.hdf' % {'stack': stack, 'sec': sec})\n",
    "    # save_hdf(hists_arr2, output_dir + '/%(stack)s_%(sec)04d_roi1_histograms_l2.hdf' % {'stack': stack, 'sec': sec})\n",
    "    \n",
    "sys.stderr.write('Total done in %f seconds\\n' % (time.time() - total_t)) # ~ 18 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labelmap_viz = colors[labelmap]\n",
    "# # display_image(labelmap_viz[5000:5500, 5000:5500])\n",
    "\n",
    "# plt.figure(figsize=(10,10));\n",
    "# plt.imshow(labelmap_viz[5000:5500, 5000:5500]);\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Compute histograms (method 1, slow)\n",
    "\n",
    "# def f(x,y):\n",
    "#     return np.bincount(labelmap[y-half_size:y+half_size-1, x-half_size:x+half_size-1].flat, minlength=M+1)[1:]\n",
    "\n",
    "# t = time.time()\n",
    "# sample_hists_list = []\n",
    "\n",
    "# for s in range(0, len(indices_roi), 100):\n",
    "#     res = Parallel(n_jobs=16)(delayed(f)(x,y) for x, y in sample_locations[indices_roi][s:s+100])\n",
    "#     sample_hists_list.append(res)\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # ~ 72 seconds\n",
    "\n",
    "# from itertools import chain\n",
    "# sample_hists = list(chain(*sample_hists_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Compute histograms (method 2, fast), level-0\n",
    "\n",
    "# sample_locs_roi = sample_locations[indices_roi]\n",
    "# patch_xmin = sample_locs_roi[:,0] - half_size\n",
    "# patch_ymin = sample_locs_roi[:,1] - half_size\n",
    "# patch_xmax = sample_locs_roi[:,0] + half_size\n",
    "# patch_ymax = sample_locs_roi[:,1] + half_size\n",
    "\n",
    "# def compute_histogram_particular_label(i):\n",
    "#     '''\n",
    "#     Compute the histogram of label i using integral image.\n",
    "#     '''\n",
    "#     m = (labelmap == i).astype(np.uint8)\n",
    "#     mi = cv2.integral(m)\n",
    "#     ci = mi[patch_ymin, patch_xmin] + mi[patch_ymax, patch_xmax] - mi[patch_ymax, patch_xmin] - mi[patch_ymin, patch_xmax]\n",
    "#     return ci\n",
    "\n",
    "# t = time.time()\n",
    "# hists = Parallel(n_jobs=16)(delayed(compute_histogram_particular_label)(i) for i in range(1, M+1))\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # ~ 18 seconds\n",
    "\n",
    "# hists_arr = np.array(hists).T\n",
    "# print hists_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Compute histograms (method 2), for all levels\n",
    "\n",
    "# sample_locs_roi = sample_locations[indices_roi]\n",
    "\n",
    "# # compute level-2 histograms\n",
    "# l = 2\n",
    "\n",
    "# grid_size = patch_size / 2**l\n",
    "\n",
    "# if l == 2:\n",
    "#     rx = [-2, -1, 0, 1]\n",
    "#     ry = [-2, -1, 0, 1]\n",
    "# elif l == 1:\n",
    "#     rx = [-1, 0]\n",
    "#     ry = [-1, 0]\n",
    "# elif l == 0:\n",
    "#     rx = [-.5]\n",
    "#     ry = [-.5]\n",
    "\n",
    "# rxs, rys = np.meshgrid(rx, ry)\n",
    "\n",
    "# patch_coords_allGrid = []\n",
    "\n",
    "# for grid_i, (rx, ry) in enumerate(np.c_[rxs.flat, rys.flat]):\n",
    "    \n",
    "#     patch_xmin = sample_locs_roi[:,0] + rx * grid_size\n",
    "#     patch_ymin = sample_locs_roi[:,1] + ry * grid_size\n",
    "#     patch_xmax = sample_locs_roi[:,0] + (rx + 1) * grid_size\n",
    "#     patch_ymax = sample_locs_roi[:,1] + (ry + 1) * grid_size\n",
    "    \n",
    "#     patch_coords_allGrid.append([patch_xmin, patch_ymin, patch_xmax, patch_ymax])\n",
    "    \n",
    "    \n",
    "# all_coords = np.hstack(patch_coords_allGrid)\n",
    "# patch_xmin = all_coords[0]\n",
    "# patch_ymin = all_coords[1]\n",
    "# patch_xmax = all_coords[2]\n",
    "# patch_ymax = all_coords[3]\n",
    "\n",
    "# def compute_histogram_particular_label(i):\n",
    "#     m = (labelmap == i).astype(np.uint8)\n",
    "#     mi = cv2.integral(m)\n",
    "#     ci = mi[patch_ymin, patch_xmin] + mi[patch_ymax, patch_xmax] - mi[patch_ymax, patch_xmin] - mi[patch_ymin, patch_xmax]\n",
    "#     return ci\n",
    "\n",
    "# t = time.time()\n",
    "# hists = Parallel(n_jobs=16)(delayed(compute_histogram_particular_label)(i) for i in range(1, M+1))\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # ~ 18 seconds\n",
    "\n",
    "# n_grid = (2**l)**2\n",
    "# hists_arr2 = np.transpose(np.reshape(hists, (M, n_grid, -1)))\n",
    "# print hists_arr2.shape\n",
    "\n",
    "# # compute level-1 histograms based on level-2 histograms\n",
    "\n",
    "# hists_arr1 = np.transpose([hists_arr2[:, [0,1,4,5], :].sum(axis=1),\n",
    "#                            hists_arr2[:, [2,3,6,7], :].sum(axis=1),\n",
    "#                            hists_arr2[:, [8,9,12,13], :].sum(axis=1),\n",
    "#                            hists_arr2[:, [10,11,14,15], :].sum(axis=1)], \n",
    "#                           [1,0,2])\n",
    "# print hists_arr1.shape\n",
    "\n",
    "# # compute level-0 histograms based on level-1 histograms\n",
    "\n",
    "# hists_arr0 = hists_arr1.sum(axis=1)\n",
    "# print hists_arr0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
